{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T12:54:49.334286Z",
     "iopub.status.busy": "2025-04-04T12:54:49.333816Z",
     "iopub.status.idle": "2025-04-04T12:54:49.973500Z",
     "shell.execute_reply": "2025-04-04T12:54:49.972489Z",
     "shell.execute_reply.started": "2025-04-04T12:54:49.334258Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/cifake-real-and-ai-generated-synthetic-images\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"birdy654/cifake-real-and-ai-generated-synthetic-images\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T12:54:51.497912Z",
     "iopub.status.busy": "2025-04-04T12:54:51.497571Z",
     "iopub.status.idle": "2025-04-04T12:54:51.503484Z",
     "shell.execute_reply": "2025-04-04T12:54:51.502691Z",
     "shell.execute_reply.started": "2025-04-04T12:54:51.497884Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/input/cifake-real-and-ai-generated-synthetic-images'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T12:54:52.950084Z",
     "iopub.status.busy": "2025-04-04T12:54:52.949766Z",
     "iopub.status.idle": "2025-04-04T12:54:53.085522Z",
     "shell.execute_reply": "2025-04-04T12:54:53.084690Z",
     "shell.execute_reply.started": "2025-04-04T12:54:52.950059Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls '/kaggle/input/cifake-real-and-ai-generated-synthetic-images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-04T12:54:54.425136Z",
     "iopub.status.busy": "2025-04-04T12:54:54.424819Z",
     "iopub.status.idle": "2025-04-04T12:54:54.436446Z",
     "shell.execute_reply": "2025-04-04T12:54:54.435720Z",
     "shell.execute_reply.started": "2025-04-04T12:54:54.425108Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "data_dir = str(path)\n",
    "\n",
    "training_dir = os.path.join(data_dir,\"train\")\n",
    "if not os.path.isdir(training_dir):\n",
    "  os.mkdir(training_dir)\n",
    "\n",
    "dog_training_dir = os.path.join(training_dir,\"REAL\")\n",
    "if not os.path.isdir(dog_training_dir):\n",
    "  os.mkdir(dog_training_dir)\n",
    "\n",
    "\n",
    "cat_training_dir = os.path.join(training_dir,\"FAKE\")\n",
    "if not os.path.isdir(cat_training_dir):\n",
    "  os.mkdir(cat_training_dir)\n",
    "\n",
    "\n",
    "validation_dir = os.path.join(data_dir,\"test\")\n",
    "if not os.path.isdir(validation_dir):\n",
    "  os.mkdir(validation_dir)\n",
    "\n",
    "dog_validation_dir = os.path.join(validation_dir,\"REAL\")\n",
    "if not os.path.isdir(dog_validation_dir):\n",
    "  os.mkdir(dog_validation_dir)\n",
    "\n",
    "\n",
    "cat_validation_dir = os.path.join(validation_dir,\"FAKE\")\n",
    "if not os.path.isdir(cat_validation_dir):\n",
    "  os.mkdir(cat_validation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T12:54:57.162476Z",
     "iopub.status.busy": "2025-04-04T12:54:57.162155Z",
     "iopub.status.idle": "2025-04-04T12:54:57.169644Z",
     "shell.execute_reply": "2025-04-04T12:54:57.168755Z",
     "shell.execute_reply.started": "2025-04-04T12:54:57.162453Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "split_size = 0.80\n",
    "cat_imgs_size = len(glob.glob(\"/content/data/train/FAKE*\"))\n",
    "dog_imgs_size = len(glob.glob(\"/content/data/train/REAL*\"))\n",
    "\n",
    "for i,img in enumerate(glob.glob(\"/content/data/train/FAKE*\")):\n",
    "  if i < (cat_imgs_size * split_size):\n",
    "    shutil.move(img,cat_training_dir)\n",
    "  else:\n",
    "    shutil.move(img,cat_validation_dir)\n",
    "\n",
    "for i,img in enumerate(glob.glob(\"/content/data/train/REAL*\")):\n",
    "  if i < (dog_imgs_size * split_size):\n",
    "    shutil.move(img,dog_training_dir)\n",
    "  else:\n",
    "    shutil.move(img,dog_validation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T12:55:00.489855Z",
     "iopub.status.busy": "2025-04-04T12:55:00.489560Z",
     "iopub.status.idle": "2025-04-04T12:56:01.137810Z",
     "shell.execute_reply": "2025-04-04T12:56:01.137109Z",
     "shell.execute_reply.started": "2025-04-04T12:55:00.489835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "traindir = path+\"/train\"\n",
    "testdir = path+\"/test\"\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                       transforms.ToTensor(),                                \n",
    "                                       torchvision.transforms.Normalize(\n",
    "                                           mean=[0.485, 0.456, 0.406],\n",
    "                                           std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "                                       ])\n",
    "test_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      torchvision.transforms.Normalize(\n",
    "                                          mean=[0.485, 0.456, 0.406],\n",
    "                                          std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "                                      ])\n",
    "\n",
    "train_data = datasets.ImageFolder(traindir,transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(testdir,transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, shuffle = True, batch_size=16)\n",
    "testloader = torch.utils.data.DataLoader(test_data, shuffle = True, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T12:56:11.815228Z",
     "iopub.status.busy": "2025-04-04T12:56:11.814667Z",
     "iopub.status.idle": "2025-04-04T12:56:11.820038Z",
     "shell.execute_reply": "2025-04-04T12:56:11.818970Z",
     "shell.execute_reply.started": "2025-04-04T12:56:11.815175Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def make_train_step(model, optimizer, loss_fn):\n",
    "  def train_step(x,y):\n",
    "    yhat = model(x)\n",
    "    model.train()\n",
    "    loss = loss_fn(yhat,y)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    #optimizer.cleargrads()\n",
    "\n",
    "    return loss\n",
    "  return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T12:56:24.422670Z",
     "iopub.status.busy": "2025-04-04T12:56:24.422329Z",
     "iopub.status.idle": "2025-04-04T12:56:24.664399Z",
     "shell.execute_reply": "2025-04-04T12:56:24.663683Z",
     "shell.execute_reply.started": "2025-04-04T12:56:24.422644Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "for params in model.parameters():\n",
    "  params.requires_grad_ = False\n",
    "\n",
    "nr_filters = model.fc.in_features \n",
    "model.fc = nn.Linear(nr_filters, 1)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T12:56:26.628077Z",
     "iopub.status.busy": "2025-04-04T12:56:26.627763Z",
     "iopub.status.idle": "2025-04-04T12:56:26.632616Z",
     "shell.execute_reply": "2025-04-04T12:56:26.631736Z",
     "shell.execute_reply.started": "2025-04-04T12:56:26.628054Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import BCEWithLogitsLoss\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "loss_fn = BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters()) \n",
    "\n",
    "train_step = make_train_step(model, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T12:56:29.126146Z",
     "iopub.status.busy": "2025-04-04T12:56:29.125852Z",
     "iopub.status.idle": "2025-04-04T12:57:41.905138Z",
     "shell.execute_reply": "2025-04-04T12:57:41.904311Z",
     "shell.execute_reply.started": "2025-04-04T12:56:29.126124Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fecf91831327>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set model to train mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \"\"\"\n\u001b[1;32m    244\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3478\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3480\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3482\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!pip install tqdm\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "epoch_train_losses = []\n",
    "epoch_test_losses = []\n",
    "\n",
    "n_epochs = 10\n",
    "early_stopping_tolerance = 3\n",
    "early_stopping_threshold = 0.03\n",
    "early_stopping_counter = 0  \n",
    "\n",
    "best_loss = float(\"inf\")  \n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    model.train()  \n",
    "\n",
    "    for i, data in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
    "        x_batch, y_batch = data\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.unsqueeze(1).float().to(device)\n",
    "\n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        epoch_loss += loss / len(trainloader)\n",
    "        losses.append(loss)\n",
    "\n",
    "    epoch_train_losses.append(epoch_loss)\n",
    "    print(f\"\\nEpoch: {epoch+1}, train loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        cum_loss = 0\n",
    "        for x_batch, y_batch in testloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.unsqueeze(1).float().to(device)\n",
    "\n",
    "            yhat = model(x_batch)\n",
    "            val_loss = loss_fn(yhat, y_batch)\n",
    "            cum_loss += val_loss.item() / len(testloader)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "        epoch_test_losses.append(cum_loss)\n",
    "        print(f\"Epoch: {epoch+1}, val loss: {cum_loss:.4f}\")\n",
    "\n",
    "        if cum_loss < best_loss:\n",
    "            best_loss = cum_loss\n",
    "            best_model_wts = model.state_dict()\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        if early_stopping_counter == early_stopping_tolerance or best_loss <= early_stopping_threshold:\n",
    "            print(\"\\nTerminating: early stopping\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(best_model_wts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T13:00:51.514501Z",
     "iopub.status.busy": "2025-04-04T13:00:51.514093Z",
     "iopub.status.idle": "2025-04-04T13:00:51.883630Z",
     "shell.execute_reply": "2025-04-04T13:00:51.882714Z",
     "shell.execute_reply.started": "2025-04-04T13:00:51.514470Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr  4 13:00:51 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P0             32W /  250W |     929MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T13:52:03.047692Z",
     "iopub.status.busy": "2025-04-04T13:52:03.047345Z",
     "iopub.status.idle": "2025-04-04T14:32:23.869395Z",
     "shell.execute_reply": "2025-04-04T14:32:23.868306Z",
     "shell.execute_reply.started": "2025-04-04T13:52:03.047664Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [07:21<00:00, 14.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1, train loss: 0.3295\n",
      "Epoch: 1, val loss: 0.2714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [07:49<00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2, train loss: 0.3302\n",
      "Epoch: 2, val loss: 0.2683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [06:44<00:00, 15.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3, train loss: 0.3320\n",
      "Epoch: 3, val loss: 0.2689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [06:30<00:00, 15.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4, train loss: 0.3316\n",
      "Epoch: 4, val loss: 0.2745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [06:30<00:00, 16.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5, train loss: 0.3331\n",
      "Epoch: 5, val loss: 0.2716\n",
      "\n",
      "Terminating: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "!pip install tqdm\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "epoch_train_losses = []\n",
    "epoch_test_losses = []\n",
    "\n",
    "n_epochs = 10\n",
    "early_stopping_tolerance = 3\n",
    "early_stopping_threshold = 0.03\n",
    "early_stopping_counter = 0\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()  \n",
    "\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, data in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
    "        x_batch, y_batch = data\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.unsqueeze(1).float().to(device)\n",
    "\n",
    "        loss = train_step(x_batch, y_batch) \n",
    "        loss_value = loss.item()            \n",
    "\n",
    "        epoch_loss += loss_value / len(trainloader)\n",
    "        losses.append(loss_value)           \n",
    "    epoch_train_losses.append(epoch_loss)\n",
    "    print(f\"\\nEpoch: {epoch+1}, train loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        cum_loss = 0\n",
    "        for x_batch, y_batch in testloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.unsqueeze(1).float().to(device)\n",
    "\n",
    "            yhat = model(x_batch)\n",
    "            val_loss = loss_fn(yhat, y_batch)\n",
    "            val_loss_value = val_loss.item()                     \n",
    "            cum_loss += val_loss_value / len(testloader)\n",
    "            val_losses.append(val_loss_value)                    \n",
    "\n",
    "        epoch_test_losses.append(cum_loss)\n",
    "        print(f\"Epoch: {epoch+1}, val loss: {cum_loss:.4f}\")\n",
    "\n",
    "        if cum_loss < best_loss:\n",
    "            best_loss = cum_loss\n",
    "            best_model_wts = model.state_dict()\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        if early_stopping_counter == early_stopping_tolerance or best_loss <= early_stopping_threshold:\n",
    "            print(\"\\nTerminating: early stopping\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(best_model_wts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T14:34:04.284009Z",
     "iopub.status.busy": "2025-04-04T14:34:04.283650Z",
     "iopub.status.idle": "2025-04-04T14:34:04.364630Z",
     "shell.execute_reply": "2025-04-04T14:34:04.363652Z",
     "shell.execute_reply.started": "2025-04-04T14:34:04.283981Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model.state_dict(), \"my_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T14:34:16.117938Z",
     "iopub.status.busy": "2025-04-04T14:34:16.117620Z",
     "iopub.status.idle": "2025-04-04T14:34:16.821580Z",
     "shell.execute_reply": "2025-04-04T14:34:16.820869Z",
     "shell.execute_reply.started": "2025-04-04T14:34:16.117913Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from safetensors.torch import save_file\n",
    "\n",
    "save_file(model.state_dict(), \"my_model.safetensors\")\n",
    "\n",
    "import h5py\n",
    "\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "with h5py.File(\"my_model.h5\", \"w\") as f:\n",
    "    for key, tensor in state_dict.items():\n",
    "        f.create_dataset(key, data=tensor.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T14:40:54.022447Z",
     "iopub.status.busy": "2025-04-04T14:40:54.021956Z",
     "iopub.status.idle": "2025-04-04T14:40:54.031801Z",
     "shell.execute_reply": "2025-04-04T14:40:54.030996Z",
     "shell.execute_reply.started": "2025-04-04T14:40:54.022406Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#inference\n",
    "import os\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, folder, transform):\n",
    "        self.paths = [os.path.join(folder, f) for f in os.listdir(folder)\n",
    "                      if f.lower().endswith((\"png\", \"jpg\", \"jpeg\"))]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "        return self.transform(img), self.paths[idx]\n",
    "\n",
    "def run_inference(image_folder, output_csv=\"predictions.csv\"):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    dataset = InferenceDataset(image_folder, transform)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for img, path in loader:\n",
    "            img = img.to(device)\n",
    "            pred = torch.sigmoid(model(img)).item()\n",
    "            label = \"REAL\" if pred >= 0.5 else \"FAKE\"\n",
    "            results.append({\"image_path\": path[0], \"prediction\": label, \"score\": pred})\n",
    "\n",
    "    pd.DataFrame(results).to_csv(output_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T14:41:16.510441Z",
     "iopub.status.busy": "2025-04-04T14:41:16.510058Z",
     "iopub.status.idle": "2025-04-04T14:41:17.143128Z",
     "shell.execute_reply": "2025-04-04T14:41:17.142398Z",
     "shell.execute_reply.started": "2025-04-04T14:41:16.510411Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "final_path = \"/kaggle/input/finald/Test datasets/Test_dataset_2\"\n",
    "run_inference(final_path, \"outputdata1.csv\")\n",
    "run_inference(final_path, \"outputdata2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3041726,
     "sourceId": 5256696,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7049439,
     "sourceId": 11276085,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
